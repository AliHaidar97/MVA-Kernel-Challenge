{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import utils\n",
    "import models\n",
    "import kernels.KShortestPathKernel as KShortestPathKernel\n",
    "import kernels.ShortestPathKernel as  ShortestPathKernel\n",
    "import kernels.RandomWalkKernel as RandomWalkKernel\n",
    "import kernels.WalkKernel as WalkKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "with open(path + 'training_data.pkl', 'rb') as file: \n",
    "    train_graphs = pkl.load(file) \n",
    "\n",
    "with open(path + 'test_data.pkl', 'rb') as file: \n",
    "    test_graphs = pkl.load(file) \n",
    "    \n",
    "with open(path + 'training_labels.pkl', 'rb') as file: \n",
    "    train_labels = pkl.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for G in train_graphs:\n",
    "    for e in G.nodes:\n",
    "        G.nodes[e]['labels'] = [G.nodes[e]['labels'][0], 1]\n",
    "\n",
    "for G in test_graphs:\n",
    "    for e in G.nodes:\n",
    "        G.nodes[e]['labels'] = [G.nodes[e]['labels'][0], 1]\n",
    "\n",
    "for G in train_graphs:\n",
    "    for e in G.edges:\n",
    "        G.edges[e]['labels'] = G.edges[e]['labels'][0] + 1\n",
    "\n",
    "for G in test_graphs:\n",
    "    for e in G.edges:\n",
    "        G.edges[e]['labels'] = G.edges[e]['labels'][0] + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def morgan_index(graphs):\n",
    "    \n",
    "    for (i,G) in enumerate(graphs):\n",
    "        K = copy.deepcopy(G)\n",
    "        for node in G.nodes:\n",
    "            K.nodes[node]['labels'][1] = 0\n",
    "            for x in G.neighbors(node):\n",
    "                K.nodes[node]['labels'][1]  += G.nodes[x]['labels'][1]\n",
    "        graphs[i] = K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    morgan_index(train_graphs)\n",
    "    morgan_index(test_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_train = []\n",
    "zero_train = []\n",
    "for (i,G) in enumerate(train_graphs):\n",
    "    if(train_labels[i] == 0):\n",
    "        zero_train.append(G)\n",
    "    else:\n",
    "        one_train.append(G)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5445\n",
      "555\n"
     ]
    }
   ],
   "source": [
    "print(len(zero_train))\n",
    "print(len(one_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(zero_train)//9\n",
    "  \n",
    "# using list comprehension\n",
    "chunck_train = [zero_train[i:i + n] for i in range(0, len(zero_train), n)]\n",
    "#chunck_train[-2] += chunck_train[-1]\n",
    "#chunck_train = chunck_train[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graphs = []\n",
    "train_labels = []\n",
    "\n",
    "for G in chunck_train:\n",
    "    train_graphs.append(one_train + G)\n",
    "    train_labels.append([1]*len(one_train) + [0]*len(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([605, 555], dtype=int64))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels[-1], return_counts= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'is_multigraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aliha\\OneDrive\\Desktop\\MVA\\P2-Kernel Methods\\project\\main.ipynb Cell 13\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m randomWalk \u001b[39m=\u001b[39m WalkKernel\u001b[39m.\u001b[39mWalkKernel(maxK \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m)  \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m shortestPath \u001b[39m=\u001b[39m ShortestPathKernel\u001b[39m.\u001b[39mShortestPath()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m K_train \u001b[39m=\u001b[39m shortestPath\u001b[39m.\u001b[39mcompute_kernel(train_graphs,train_graphs)\n",
      "File \u001b[1;32mc:\\Users\\aliha\\OneDrive\\Desktop\\MVA\\P2-Kernel Methods\\project\\kernels\\ShortestPathKernel.py:67\u001b[0m, in \u001b[0;36mShortestPath.compute_kernel\u001b[1;34m(self, list_graph_a, list_graph_b)\u001b[0m\n\u001b[0;32m     65\u001b[0m freq_list_a \u001b[39m=\u001b[39m []\n\u001b[0;32m     66\u001b[0m freq_list_b \u001b[39m=\u001b[39m []  \n\u001b[1;32m---> 67\u001b[0m freq_list_a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_freq_walk_list(list_graph_a)\n\u001b[0;32m     68\u001b[0m freq_list_b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_freq_walk_list(list_graph_b)\n\u001b[0;32m     70\u001b[0m \u001b[39m# compute the kernel value for each pair of graphs in list_graph_a and list_graph_b\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aliha\\OneDrive\\Desktop\\MVA\\P2-Kernel Methods\\project\\kernels\\ShortestPathKernel.py:35\u001b[0m, in \u001b[0;36mShortestPath.generate_freq_walk_list\u001b[1;34m(self, list_graph)\u001b[0m\n\u001b[0;32m     31\u001b[0m freq_list \u001b[39m=\u001b[39m []\n\u001b[0;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m G \u001b[39min\u001b[39;00m tqdm(list_graph):\n\u001b[0;32m     33\u001b[0m     \n\u001b[0;32m     34\u001b[0m     \u001b[39m# Calculates the shortest paths from each node to every other node in the graph.\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     path_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39;49m(nx\u001b[39m.\u001b[39;49mall_pairs_dijkstra_path(G, weight\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     36\u001b[0m     freq \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[0;32m     38\u001b[0m     \u001b[39m# For each pair of nodes in the graph\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:1113\u001b[0m, in \u001b[0;36mall_pairs_dijkstra_path\u001b[1;34m(G, cutoff, weight)\u001b[0m\n\u001b[0;32m   1111\u001b[0m \u001b[39m# TODO This can be trivially parallelized.\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m G:\n\u001b[1;32m-> 1113\u001b[0m     \u001b[39myield\u001b[39;00m (n, path(G, n, cutoff\u001b[39m=\u001b[39;49mcutoff, weight\u001b[39m=\u001b[39;49mweight))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:302\u001b[0m, in \u001b[0;36msingle_source_dijkstra_path\u001b[1;34m(G, source, cutoff, weight)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msingle_source_dijkstra_path\u001b[39m(G, source, cutoff\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, weight\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    242\u001b[0m     \u001b[39m\"\"\"Find shortest weighted paths in G from a source node.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[0;32m    244\u001b[0m \u001b[39m    Compute shortest path between source and all other reachable\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    300\u001b[0m \n\u001b[0;32m    301\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m     \u001b[39mreturn\u001b[39;00m multi_source_dijkstra_path(G, {source}, cutoff\u001b[39m=\u001b[39;49mcutoff, weight\u001b[39m=\u001b[39;49mweight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:546\u001b[0m, in \u001b[0;36mmulti_source_dijkstra_path\u001b[1;34m(G, sources, cutoff, weight)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmulti_source_dijkstra_path\u001b[39m(G, sources, cutoff\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, weight\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39m\"\"\"Find shortest weighted paths in G from a given set of source\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \u001b[39m    nodes.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m \n\u001b[0;32m    545\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 546\u001b[0m     length, path \u001b[39m=\u001b[39m multi_source_dijkstra(G, sources, cutoff\u001b[39m=\u001b[39;49mcutoff, weight\u001b[39m=\u001b[39;49mweight)\n\u001b[0;32m    547\u001b[0m     \u001b[39mreturn\u001b[39;00m path\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:737\u001b[0m, in \u001b[0;36mmulti_source_dijkstra\u001b[1;34m(G, sources, target, cutoff, weight)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[39mif\u001b[39;00m target \u001b[39min\u001b[39;00m sources:\n\u001b[0;32m    736\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39m0\u001b[39m, [target])\n\u001b[1;32m--> 737\u001b[0m weight \u001b[39m=\u001b[39m _weight_function(G, weight)\n\u001b[0;32m    738\u001b[0m paths \u001b[39m=\u001b[39m {source: [source] \u001b[39mfor\u001b[39;00m source \u001b[39min\u001b[39;00m sources}  \u001b[39m# dictionary of paths\u001b[39;00m\n\u001b[0;32m    739\u001b[0m dist \u001b[39m=\u001b[39m _dijkstra_multisource(\n\u001b[0;32m    740\u001b[0m     G, sources, weight, paths\u001b[39m=\u001b[39mpaths, cutoff\u001b[39m=\u001b[39mcutoff, target\u001b[39m=\u001b[39mtarget\n\u001b[0;32m    741\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:76\u001b[0m, in \u001b[0;36m_weight_function\u001b[1;34m(G, weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m weight\n\u001b[0;32m     73\u001b[0m \u001b[39m# If the weight keyword argument is not callable, we assume it is a\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[39m# string representing the edge attribute containing the weight of\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39m# the edge.\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m \u001b[39mif\u001b[39;00m G\u001b[39m.\u001b[39;49mis_multigraph():\n\u001b[0;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m u, v, d: \u001b[39mmin\u001b[39m(attr\u001b[39m.\u001b[39mget(weight, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m d\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m u, v, data: data\u001b[39m.\u001b[39mget(weight, \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'is_multigraph'"
     ]
    }
   ],
   "source": [
    "randomWalk = WalkKernel.WalkKernel(maxK = 100)  \n",
    "shortestPath = ShortestPathKernel.ShortestPath()\n",
    "K_train = shortestPath.compute_kernel(train_graphs,train_graphs)  + randomWalk.compute_kernel(train_graphs,train_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "import numpy as np\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "from sklearn.base import BaseEstimator\n",
    "def to_binary(y):\n",
    "    return ((y + 1) / 2).astype(int)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "class KernelSVC(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, C, epsilon = 1e-3):\n",
    "        self.type = 'non-linear'\n",
    "        self.C = C                                     \n",
    "        self.alpha = None\n",
    "        self.epsilon = epsilon\n",
    "        self.norm_f = None\n",
    "        self.a = None\n",
    "       \n",
    "    \n",
    "    def fit(self, K_train, y):\n",
    "        \n",
    "\n",
    "        y = np.array(y)\n",
    "       \n",
    "        #### You might define here any variable needed for the rest of the code\n",
    "        N = len(y)\n",
    "        \n",
    "        K_train += 1   \n",
    "        \n",
    "        # Set up quadratic programming problem\n",
    "        P = cvxopt.matrix(np.outer(y, y) * K_train)\n",
    "        q = cvxopt.matrix(-1 * np.ones(N))\n",
    "        G = cvxopt.matrix(np.vstack((-1 * np.eye(N), np.eye(N))))\n",
    "        h = cvxopt.matrix(np.hstack((np.zeros(N), self.C * np.ones(N))))\n",
    "        A = cvxopt.matrix(y.reshape(1, -1)) * 1.0\n",
    "        b = cvxopt.matrix(np.zeros(1))\n",
    "        # Solve the quadratic program using cvxopt       \n",
    "        cvxopt.solvers.options['show_progress'] = True\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        # Lagrange multipliers\n",
    "        self.alpha = np.ravel(solution['x'])\n",
    "        \n",
    "        \n",
    "        #clip\n",
    "        self.alpha[self.alpha < 1e-5] = 0\n",
    "        ## Assign the required attributes\n",
    "        self.a = np.diag(y)@self.alpha \n",
    "        f = K_train@self.a\n",
    "        mask = ((self.alpha < self.C) & (self.alpha > 0))\n",
    "        self.b =  np.median((1 - y[mask]*f[mask])/y[mask]) #''' -----------------offset of the classifier------------------ '''\n",
    "        self.norm_f = self.a.T@K_train@self.a   #'''------------------------RKHS norm of the function f ------------------------------'''\n",
    "       \n",
    "\n",
    "    ### Implementation of the separting function $f$ \n",
    "    def separating_function(self, K_test):\n",
    "        # Input : matrix x of shape N data points times d dimension\n",
    "        # Output: vector of size N\n",
    "        K_test += 1\n",
    "        return K_test@self.a\n",
    "    \n",
    "    \n",
    "    def predict(self, K_test):\n",
    "        \"\"\" Predict y values in {-1, 1} \"\"\"\n",
    "        d = self.separating_function(K_test)\n",
    "        return 2 * ((d+self.b)> 0) - 1\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        d = self.separating_function(X)\n",
    "        return sigmoid(d + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_train = 2*y_train-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,) (800, 1000)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (800,800) (800,1000) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aliha\\OneDrive\\Desktop\\MVA\\P2-Kernel Methods\\project\\main.ipynb Cell 13\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     s \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     skf \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, random_state\u001b[39m=\u001b[39mi, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     score \u001b[39m=\u001b[39m cross_val_score(KernelSVC(C \u001b[39m=\u001b[39m C), K_train, y_train, cv\u001b[39m=\u001b[39mskf, scoring \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mroc_auc\u001b[39m\u001b[39m'\u001b[39m,error_score\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     s\u001b[39m.\u001b[39mappend(score\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m scores\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mmean(s))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "\u001b[1;32mc:\\Users\\aliha\\OneDrive\\Desktop\\MVA\\P2-Kernel Methods\\project\\main.ipynb Cell 13\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X13sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m K_train \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m   \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Set up quadratic programming problem\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m P \u001b[39m=\u001b[39m cvxopt\u001b[39m.\u001b[39mmatrix(np\u001b[39m.\u001b[39;49mouter(y, y) \u001b[39m*\u001b[39;49m K_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m q \u001b[39m=\u001b[39m cvxopt\u001b[39m.\u001b[39mmatrix(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mones(N))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m G \u001b[39m=\u001b[39m cvxopt\u001b[39m.\u001b[39mmatrix(np\u001b[39m.\u001b[39mvstack((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39meye(N), np\u001b[39m.\u001b[39meye(N))))\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (800,800) (800,1000) "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "c = np.arange(1,1.5,0.01)\n",
    "scores = []\n",
    "for C in tqdm(c):\n",
    "    for i in range(2):\n",
    "        s = []\n",
    "        skf = KFold(n_splits=5, random_state=i, shuffle=True)\n",
    "        score = cross_val_score(SVC(C = C, kernel='precomputed',  probability=True, class_weight='balanced'), K_train, train_labels, cv=skf, scoring = 'roc_auc')\n",
    "        s.append(score.reshape(-1))\n",
    "    scores.append(np.mean(s))\n",
    "\n",
    "C =  c[np.argsort(scores)[-1]]\n",
    "print(scores)\n",
    "print(C,np.sort(scores)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4900000000000004 0.910652782919979\n"
     ]
    }
   ],
   "source": [
    "print(C,np.sort(scores)[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 147/2000 [00:02<00:27, 66.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aliha\\OneDrive\\Desktop\\MVA\\P2-Kernel Methods\\project\\main.ipynb Cell 15\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aliha/OneDrive/Desktop/MVA/P2-Kernel%20Methods/project/main.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m K_test \u001b[39m=\u001b[39m shortestPath\u001b[39m.\u001b[39mcompute_kernel(test_graphs,train_graphs)  \u001b[39m+\u001b[39m randomWalk\u001b[39m.\u001b[39mcompute_kernel(test_graphs,train_graphs)\n",
      "File \u001b[1;32mc:\\Users\\aliha\\OneDrive\\Desktop\\MVA\\P2-Kernel Methods\\project\\kernels\\ShortestPathKernel.py:67\u001b[0m, in \u001b[0;36mShortestPath.compute_kernel\u001b[1;34m(self, list_graph_a, list_graph_b)\u001b[0m\n\u001b[0;32m     65\u001b[0m freq_list_a \u001b[39m=\u001b[39m []\n\u001b[0;32m     66\u001b[0m freq_list_b \u001b[39m=\u001b[39m []  \n\u001b[1;32m---> 67\u001b[0m freq_list_a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_freq_walk_list(list_graph_a)\n\u001b[0;32m     68\u001b[0m freq_list_b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_freq_walk_list(list_graph_b)\n\u001b[0;32m     70\u001b[0m \u001b[39m# compute the kernel value for each pair of graphs in list_graph_a and list_graph_b\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aliha\\OneDrive\\Desktop\\MVA\\P2-Kernel Methods\\project\\kernels\\ShortestPathKernel.py:46\u001b[0m, in \u001b[0;36mShortestPath.generate_freq_walk_list\u001b[1;34m(self, list_graph)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m# Convert the shortest path between node i and node j to a string sequence representation.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m seq \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_seq(G,path_dict[i][j])\n\u001b[0;32m     47\u001b[0m \u001b[39mif\u001b[39;00m(seq \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m freq):\n\u001b[0;32m     48\u001b[0m     freq[seq] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aliha\\OneDrive\\Desktop\\MVA\\P2-Kernel Methods\\project\\kernels\\ShortestPathKernel.py:25\u001b[0m, in \u001b[0;36mShortestPath.to_seq\u001b[1;34m(self, G, path)\u001b[0m\n\u001b[0;32m     23\u001b[0m     seq \u001b[39m=\u001b[39m seq \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m#\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(G\u001b[39m.\u001b[39mnodes[path[i]][\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m#\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(G\u001b[39m.\u001b[39mnodes[path[i]][\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m#\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     24\u001b[0m     \u001b[39mif\u001b[39;00m(i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(path) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m---> 25\u001b[0m         seq \u001b[39m=\u001b[39m seq \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(G\u001b[39m.\u001b[39;49medges[(path[i],path[i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m])][\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]) \n\u001b[0;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m seq\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\networkx\\classes\\reportviews.py:1087\u001b[0m, in \u001b[0;36mOutEdgeView.__getitem__\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m \u001b[39m# Mapping Methods\u001b[39;00m\n\u001b[1;32m-> 1087\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, e):\n\u001b[0;32m   1088\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, \u001b[39mslice\u001b[39m):\n\u001b[0;32m   1089\u001b[0m         \u001b[39mraise\u001b[39;00m nx\u001b[39m.\u001b[39mNetworkXError(\n\u001b[0;32m   1090\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m does not support slicing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1091\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtry list(G.edges)[\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mstop\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mstep\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1092\u001b[0m         )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K_test = shortestPath.compute_kernel(test_graphs,train_graphs)  + randomWalk.compute_kernel(test_graphs,train_graphs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_labels\n",
    "y_train = np.array(y_train).reshape(-1)\n",
    "y_train = 2*y_train - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = SVC(C = C, kernel='precomputed',  probability=True)\n",
    "#clf = models.KernelSVC(C=1)\n",
    "# Fit on the train Kernel\n",
    "clf.fit(K_train, y_train)\n",
    "\n",
    "# Predict and test.\n",
    "y_pred = clf.predict(K_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification accuracy: %0.2f\" % accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "y_pred = clf.predict(K_train)\n",
    "#tn, fp, fn, tp = confusion_matrix(y_train, y_pred,normalize='true').ravel()\n",
    "confusion_matrix = confusion_matrix(y_train, y_pred,normalize='true')\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve, auc \n",
    "plot_roc_curve(clf, K_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(K_test)[:,1]\n",
    "y_pred = np.log(y_pred/(1-y_pred))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id']= np.arange(1,len(y_pred)+1)\n",
    "sub['Predicted'] = y_pred\n",
    "sub.to_csv(\"submissions/sub.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub = pd.read_csv(\"submissions/sub.csv\")\n",
    "y_sub = np.array(y_sub['Predicted'])\n",
    "y_sub[y_sub< 0 ] = 0\n",
    "y_sub[y_sub>0] = 1\n",
    "np.sum(y_sub)/len(y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub = pd.read_csv(\"submissions/sub_089.csv\")\n",
    "y_sub = np.array(y_sub['Predicted'])\n",
    "y_sub[y_sub< 0 ] = 0\n",
    "y_sub[y_sub>0] = 1\n",
    "np.sum(y_sub)/len(y_sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbccc05dc4c888eb06191605395e1f3420714a4fab311b29cb06bebce36a9c54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
